{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1752abe6-9bec-4ec5-82c3-a8a9eea8ee2b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## <font color=\"purple\"> Les opérations map et reduce </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01813a82-e96b-47c9-8c12-c0b77433e215",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Disposant de la liste suivante, proposer 3 syntaxes pour calculer la liste des carrés de ses éléments :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "649406ae-3781-4066-8e34-fef937cfc750",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "a = [1, 4, 74, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8786cd60-6ff6-429a-abd0-935693a66452",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 16, 5476, 4]\n"
     ]
    }
   ],
   "source": [
    "b = [number ** 2 for number in a]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6099ce3c-016d-4bd6-97c3-e4996e232ea5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 16, 5476, 4]\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return x ** 2\n",
    "\n",
    "print(list(map(f, a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ed4e2d6-597e-4f65-96b0-faf30d08e9ff",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "On souhaite désormais ajouter récursivement les éléments de cette nouvelle liste. Réaliser cette opération à l'aide de la fonction reduce de functools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6bf4dc6-b489-4695-944f-552c1a1fc328",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5497\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce \n",
    "\n",
    "def g(x, y):\n",
    "    return x + y\n",
    "\n",
    "c = reduce(g, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b296f82a-0424-45bf-b8f5-489bd260f3fc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "map et reduce sont des opérateurs génériques et leur combinaison permet donc de modéliser énormément de problèmes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "47b2abdb-b915-4627-b811-a63f4508f08c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Recette de MapReduce :\n",
    "\n",
    "1. L'ensemble des données à traiter est découpé en plusieurs lots ou sous-ensembles.\n",
    "\n",
    "2. Dans une première étape, l'étape MAP, l'opérationmap, spécifiée pour notre problème, est appliquée à chaque lot. Cette opération transforme la paire(clé, valeur)représentant le lot en une liste de nouvelles paires(clé, valeur)constituant ainsi des résultats intermédiaires du traitement à effectuer sur les données complètes.\n",
    "\n",
    "3. Avant d'être envoyés à l'étape REDUCE, les résultats intermédiaires sont regroupés et triés par clé. C'est l'étape de SHUFFLE and SORT.\n",
    "\n",
    "4. Enfin, l'étape REDUCE consiste à appliquer l'opération reduce, spécifiée pour notre problème, à chaque clé. Elle agrège tous les résultats intermédiaires associés à une même clé et renvoie donc pour chaque clé une valeur unique.\n",
    "\n",
    "![Schéma MapReduce](../../docs/images/schema_mapreduce.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb2ca03e-d3ca-4037-8491-13c4e4ab5b42",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Word Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca9e0728-5333-48cc-8356-43d05be987b4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "defaultdict(int) est une structure de données fournie par le module collections de Python. Il s'agit d'une sous-classe de dictionnaire qui permet de définir une valeur par défaut pour les clés qui n'existent pas.\n",
    "Il est possible de lui préciser un type de données par défaut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f72615a2-21ba-4c38-808c-b240368b2129",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b36d28af-3be5-4fd2-a2be-77c206ccc12e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "En utilisant int comme type de données par défaut (defaultdict(int)), si une clé n'existe pas dans le dictionnaire, elle sera automatiquement initialisée avec la valeur 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "72d6712c-36bb-4bcc-ad4c-5336ce5ffc16",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Ecrire une fonction Python word_cound permettant de renvoyer le defaultdict des paires mots, comptages d'un texte passé en argument. On pourra considérer que les mots sont toujours séparés par des espaces et utiliser la méthode split() pour séparer le texte en mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6bae42d-791d-4dba-96c5-6fd01769552a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def word_count(text):\n",
    "    counts = defaultdict(int)\n",
    "    for word in text.split():\n",
    "        counts[word] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1ec1921-24de-4bdd-b545-82d8f31b2f5e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[13]: defaultdict(int,\n            {'ceci': 1, 'est': 1, 'un': 2, 'texte': 1, 'et': 1, 'test': 1})"
     ]
    }
   ],
   "source": [
    "word_count(\"ceci est un texte et un test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "804ba3f0-9b4c-4fc5-8f9d-2a3ceb5903b9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Dans la suite, nous allons mettre en oeuvre le principe de MapReduce sur les paroles d'une chanson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3fec207-df3f-4d7f-a062-c52e507922e2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Nous allons supposer que nos données d'entrée ont été découpées en différents fragments et qu'une opération de simplification a été appliquée sur chaque fragment pour supprimer les caractères de ponctuation, transformer chaque mot en son singulier (\"nos\" devient \"notre\") et ne garder que les mots de plus de 3 caractères."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "442a7d24-1bd3-485e-adb2-f728c167ff7b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Voici ces morceaux :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97e66175-5682-4791-9d9e-da38ec045b2d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "D1 = {\"./lot1.txt\" : \"jour lève notre grisaille\"}\n",
    "D2 = {\"./lot2.txt\" : \"trottoir notre ruelle notre tour\"}\n",
    "D3 = {\"./lot3.txt\" : \"jour lève notre envie vous\"}\n",
    "D4 = {\"./lot4.txt\" : \"faire comprendre tous notre tour notre\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6c5b7722-938f-48c5-80cc-236de8352fd4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Ecrire une fonction map s'appliquant sur une paire clef, valeur qui renvoie le comptage des mots dans la valeur (la clef ne sera pas utilisée, ce n'est pas grave).\n",
    "Par exemple, son appel sur la clef et la valeur de D1 renverra [('jour', 1), ('lève', 1), ('notre', 1), ('grisaille', 1)]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e17f7cc-703c-4e32-9ce4-456f90baee4c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def map(key, value):\n",
    "  interm = []\n",
    "  for word in value.split():\n",
    "    interm.append((word, 1))\n",
    "  return interm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90073a09-fd29-4dfa-b268-4b6dcfa0e205",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('faire', 1), ('comprendre', 1), ('tous', 1), ('notre', 1), ('tour', 1), ('notre', 1)]\n"
     ]
    }
   ],
   "source": [
    "key, value = next(iter(D4.items()))\n",
    "print(map(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "16acb5c3-beb1-406b-81af-dda62f986ceb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "![Image map](../../docs/images/map.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac73cf09-7cf0-41d9-bd4b-28e986a2991e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "A ce stade, nous allons considérer que nous sommes un peu magicien et que nous sommes capables de regrouper et de trier, par clé commune, les résultats intermédiaires fournis par l'étape MAP. Cela correspond à l'étape SHUFFLE and SORT. Dans la pratique, cette étape est entièrement gérée par le framework d'exécution de MapReduce, de manière distribuée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ff7c651-b816-41b0-9980-6f3789337c79",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "![Shuffle and sort](../../docs/images/shuffle_sort.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2a5dc9e6-2244-41b7-a37a-cff289e5309f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Ecrire une fonction reduce prenant en arguments une clef et une liste de valeurs et retournant un tuple formé de la clef et de la somme des valeurs de la liste. Par exemple, son appel sur (\"notre\", [1, 1, 1, 1, 1]) renverra 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f955f0ea-91f1-462c-8626-999c704c8958",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def reduce(key, values):\n",
    "    return (key, sum(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01506dbf-4cc9-42ac-8ee7-c1a4cf38bcc1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('notre', 5)\n"
     ]
    }
   ],
   "source": [
    "print(reduce(\"notre\", [1, 1, 1, 1, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34dccbb6-2e81-4070-bb6c-e2dcfccf2f1f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Et voilà, nous avons notre comptage de mots !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "296ca634-951d-4636-beb6-0149c9298a33",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "![Schéma global](../../docs/images/global.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3553827-5f5b-4f65-8a1f-ee786cbc6238",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "En résumé, MapReduce c'est :\n",
    "\n",
    "- La généralisation du paradigme de conception d'algorithmes diviser pour régner au cadre distribué.\n",
    "\n",
    "- Un modèle de programmation reposant sur la combinaison de deux fonctions simples,mapetreduce, inspirées de la programmation fonctionnelle.\n",
    "\n",
    "- Un framework d'exécution prenant en charge le deploiement et la distribution des calculs sur un cluster.\n",
    "\n",
    "Le rôle des developpeurs d'applications distribuées, c'est donc de penser en MapReduce :\n",
    "\n",
    "- Choisir une manière de découper les données afin que l'opération MAP soit parallélisable.\n",
    "\n",
    "- Choisir la clé à utiliser pour le problème ciblé.\n",
    "\n",
    "- Écrire le code de la fonction pour l'opération MAP.\n",
    "\n",
    "- Écrire le code de la fonction pour l'opération REDUCE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4e66793-7ae9-4ba6-b071-da6fe84e7bcf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "spark-prise-en-main_enonce_mapreduce",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "test-yOZBwoax-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
